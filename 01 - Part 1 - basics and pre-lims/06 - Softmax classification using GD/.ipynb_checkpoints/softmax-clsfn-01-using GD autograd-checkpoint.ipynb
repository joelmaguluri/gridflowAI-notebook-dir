{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512b6242-49d0-4966-8ec9-cb9e23886e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe7edd-295d-4619-bb19-e03e84320900",
   "metadata": {},
   "source": [
    "#### Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69774e25-3a03-4b6b-8bc3-f66cce82d798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d3531c-70e1-4260-ac90-20f3d202f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf91dd7-d186-4e69-a5f1-406571f09ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the feature values\n",
    "scaler  = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e01d62-9e88-46cd-b807-f986f61230af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Perform one-hot encoding on the target variable\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f11959-b1b1-41a8-80b7-184ddd818c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the softmax function\n",
    "def softmax(z):\n",
    "    exps = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23fe6321-a945-4bef-b02c-a98da3c4ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cross-entropy loss function\n",
    "def cross_entropy_loss(theta, X, y):\n",
    "    logits        = np.dot(X, theta)\n",
    "    probabilities = softmax(logits)\n",
    "    \n",
    "    loss          = -np.mean(np.sum(y * np.log(probabilities), axis=1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207230a7-5852-425a-8ee7-7e86ee7b6bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "456a0177-e81d-40c2-bd45-042da8cde151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model parameters\n",
    "np.random.seed(42)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_classes  = len(np.unique(y_train))\n",
    "\n",
    "theta_initial = np.random.randn(num_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7e9fb66-19fc-4844-a23a-521018c7074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the gradients using autograd\n",
    "gradient = grad(cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f71f7e03-44ef-40c9-ba34-a1db503c8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform gradient descent optimization\n",
    "learning_rate  = 0.1\n",
    "num_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03f1b88c-00fd-4a9f-8388-c9cb197c33ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = theta_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2f175cb-34cf-45ba-add9-6643008f3f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\autograd\\tracer.py:48: RuntimeWarning: divide by zero encountered in log\n",
      "  return f_raw(*args, **kwargs)\n",
      "D:\\ANACONDA\\lib\\site-packages\\autograd\\tracer.py:48: RuntimeWarning: invalid value encountered in multiply\n",
      "  return f_raw(*args, **kwargs)\n",
      "D:\\ANACONDA\\lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:78: RuntimeWarning: divide by zero encountered in divide\n",
      "  defvjp(anp.log,    lambda ans, x : lambda g: g / x)\n",
      "D:\\ANACONDA\\lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:78: RuntimeWarning: overflow encountered in divide\n",
      "  defvjp(anp.log,    lambda ans, x : lambda g: g / x)\n",
      "D:\\ANACONDA\\lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:78: RuntimeWarning: invalid value encountered in divide\n",
      "  defvjp(anp.log,    lambda ans, x : lambda g: g / x)\n",
      "D:\\ANACONDA\\lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:53: RuntimeWarning: invalid value encountered in multiply\n",
      "  lambda ans, x, y : unbroadcast_f(y, lambda g: - g * x / y**2))\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iterations):\n",
    "    # Compute gradients\n",
    "    gradients = gradient(theta, X_train, y_train_encoded)\n",
    "\n",
    "    # Update parameters\n",
    "    theta -= learning_rate * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec35db5f-0d13-4be9-affb-0584ec53aa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09592857142857143\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "logits_test = np.dot(X_test, theta)\n",
    "\n",
    "probabilities_test = softmax(logits_test)\n",
    "y_pred             = np.argmax(probabilities_test, axis=1)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774d521-5b0d-4a3b-9a02-b4a1fb9dcc98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
